library(quantreg)
install.packages("quantreg")
install.packages("quantreg")
library(quantreg)
data(engel)
# Export a R dataset as a CSV file. Other software can then use this dataset.
write.csv(engel, "engel.csv", row.names = F, col.names = T)
summary(engel$income)
fit.lm <- lm(engel$foodexp ~ engel$income)
summary(fit.lm)
plot(engel$income, engel$foodexp, main = 'Regressions on Engel Food Expenditure Data', xlab = 'Household Income', ylab = 'Food Expenditure')
abline(fit.lm,lty=2,col="red")
par(mfrow=c(2,2))
plot(fit.lm)
par(mfrow=c(1,1))
library(quantreg)
# Fit 50th Percentile Line (i.e. Median)
fit.p.5 <- rq(engel$foodexp ~ engel$income, tau=.5) #tau: percentile level. 0.5 is the 50th percentile (aka median).
fit.p.5
summary(fit.p.5, se = "nid")
# 5th, 10th, 25th, 75th, 90th, 95th percentiles.
taus <- c(.05, .1, .25, .75, .90, .95)
# Plot the 6 percentile grey lines
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
# Plot the 6 percentile grey lines
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
# Plot the 6 percentile grey lines
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
summary(engel$income)
fit.lm <- lm(engel$foodexp ~ engel$income)
summary(fit.lm)
plot(engel$income, engel$foodexp, main = 'Regressions on Engel Food Expenditure Data', xlab = 'Household Income', ylab = 'Food Expenditure')
abline(fit.lm,lty=2,col="red")
par(mfrow=c(2,2))
plot(fit.lm)
par(mfrow=c(1,1))
library(quantreg)
# Fit 50th Percentile Line (i.e. Median)
fit.p.5 <- rq(engel$foodexp ~ engel$income, tau=.5) #tau: percentile level. 0.5 is the 50th percentile (aka median).
# Fit 50th Percentile Line (i.e. Median)
fit.p.5 <- rq(engel$foodexp ~ engel$income, tau=.5) #tau: percentile level. 0.5 is the 50th percentile (aka median).
# Fit 50th Percentile Line (i.e. Median)
fit.p.5 <- rq(engel$foodexp ~ engel$income, tau=.5) #tau: percentile level. 0.5 is the 50th percentile (aka median).
library(quantreg)
data(engel)
# Fit 50th Percentile Line (i.e. Median)
fit.p.5 <- rq(engel$foodexp ~ engel$income, tau=.5) #tau: percentile level. 0.5 is the 50th percentile (aka median).
fit.p.5
summary(fit.p.5)
summary(fit.p.5, se = "nid")
taus <- c(.05, .1, .25, .75, .90, .95)
# Plot the 6 percentile grey lines
for( i in 1:length(taus)){
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
# Plot the 6 percentile grey lines
for( i in 1:length(taus))
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
for( i in 1:length(taus))
{
abline(rq(engel$foodexp~engel$income,tau=taus[i]), col = "grey")
}
getwd()
setwd(/Users/luke/Desktop)
setwd(Users/luke/Desktop)
setwd("~/Desktop/home-credit-default-risk")
plot = c(2066166.93,158065.98,530097.97,13756.36,205786.48,1978.28,4715186.84)
sum(plot)
hist(plot)
scipen(1000)
options(scipen = 1000)
hist(plot)
sum3() <- function(x,y,z){
answer <- x + 2y - z
return answer
}
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
}
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
}
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
}
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
}
sum3() <- function(x,y,z){
answer <- x + 2y - z
return(answer)
}
sum3() <- function(x,y,z){
answer <- x + 2*y - z
return(answer)
}
sum3 <- function(x,y,z){
answer <- x + 2*y - z
return(answer)
}
sum3(1,-2,7)
?binomcdf
??binomcdf
?binompdf
1 - pbinom(37,52,0.5)
pbinom(37,52,0.5)
pbinom(37,52,0.5)
1 - pbinom(36,52,0.5)
cbinom(1,400,0.00159)
dbinom(1,400,0.00159)
1-pbinom(1,400,0.00159)
1-pbinom(0,400,0.00159)
source("~/Desktop/LevelUp!/EIAforecast.R", echo=TRUE)
auto.arima(df)
ts = df["Price"]
auto.arima(ts)
model = auto.arima(ts)
ts <- ts(df$Price, frequency = 365, start = c(1986,1))
ts
plot.ts(ts, ylab = "Spot Price of Crude Oil", xlab = "Year",
main = "Spot Prices of Crude Oil over time")
ts <- ts(df$Price, frequency = 365, start = c(1986,1,1))
plot.ts(ts, ylab = "Spot Price of Crude Oil", xlab = "Year",
main = "Spot Prices of Crude Oil over time")
View(ts)
library(TTR) # for moving averages
m.ma3 <- SMA(ts, n = 3*365)
plot(m.ma3, main = "Moving Avg Span 3", ylab = "MA3 Forecast")
m.ma.mul <- decompose(ts, type = "multiplicative")
autoplot(ts)
model <- auto.arima(ts)
model <- auto.arima(ts, seasonal = F)
3months <- 3*36
months_cutoff <- 3*36
ts = ts[months_cutoff:nrow(ts)]
ts = ts[months_cutoff:nrows(ts)]
nrow(ts)
df_trunc = df[months_cutoff:nrow(df)]
df_trunc = df[months_cutoff:nrow(df),]
ts = df_trunc
View(ts)
length <- nrow(df)
df_trunc = df[length-months_cutoff:length,]
ts = df_trunc
View(ts)
length
months_cutoff <- 3*36
months_cutoff
stop <- length - months_cutoff
df_trunc <- df[stop:length,]
View(df_trunc)
ts = df_trunc
View(ts)
autoplot(ts)
ts <- ts(ts)
autoplot(ts)
ts <- df_trunc$Price
ts <- ts(ts)
autoplot(ts)
model <- auto.arima(ts)
model <- auto.arima(ts, seasonal = F )
truncts <- ts(df_trunc[,'Price'],start=c(2021,12,9),frequency=1)
model <- auto.arima(truncts, seasonal = F )
print(summary(model))
checkresiduals(model)
y <- dim(trunc)[1
]
trainSet <- trunc()[1:(y-4),]
trainSet <- trunc[1:(y-4),]
trainSet <- trunc[1:(y-4),]
truncated <- df_trunc
y <- dim(truncated)[1]
trainSet <- truncated[1:(y-4),]
testSet <- truncated[(y-3):(y)]
testSet <- truncated[(y-3):(y),]
truncts <- ts(trainSet[,'Price'],start=c(2021,12,9),frequency=1)
train_trunc_ts <- ts(trainSet[,'Price'],start=c(2021,12,9),frequency=1)
model <- auto.arima(train_trunc_ts, seasonal = F )
print(summary(model))
checkresiduals(model)
forecast_number <- nrows(testSet)
forecast_number <- nrows(testSet)
forecast_number <- nrow(testSet)
fcast <- forecast(model, h = forecast_number)
plot(fcast)
autoplot(fcast) + ggtitle("Forecasted spot prices of crude oil") + ylab("Price Sales") + xlab("Days")
library(tidyverse) # in order for ggtitle()
autoplot(fcast) + ggtitle("Forecasted spot prices of crude oil") + ylab("Price Sales") + xlab("Days")
print(summary(fcast))
modelEval <- cbind(fcast$mean, testSet$ecommerce)
modelEval <- cbind(fcast$mean, testSet$Price)
colnames(modelEval) <- c("Predicted","Actual")
modelEval <- as.data.frame(modelEval)
modelEval
colnames(modelEval) <- c("Predicted","Actual")
modelEval <- cbind(fcast$mean, testSet$Price)
modelEval
